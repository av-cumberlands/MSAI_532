{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "3342cef2-0b69-4341-a6cf-bfa8faddcad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\alex-\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d7cd5b-7ee9-4368-9d63-da4f2c1568a0",
   "metadata": {},
   "source": [
    "##### 1. Load Input Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f5d9c85d-66de-4d04-933e-c33435005997",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file_path = '\\MSAI_532\\ResidencyWeekend\\text_file.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "622ce786-d2b9-410b-9592-3cc30658409a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KBR said Friday the global economic downturn so far has\n",
      "had\n",
      "little effect on its business but warned\n"
     ]
    }
   ],
   "source": [
    "with open('text_file.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "7c155ae4-02cd-45d6-949e-249ce0db2ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3052306"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3293d9-2a12-491b-9eb9-5bf21160c88a",
   "metadata": {},
   "source": [
    "##### 2. Tokenize the text into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "4d577643-a4f4-4e59-925e-cb554fe20d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 1: Using nltk\n",
    "\n",
    "words = word_tokenize(text)\n",
    "words_df = pd.DataFrame(words, columns=['Word'])\n",
    "words_df['Count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "29b9a066-e365-4b6d-81c2-d37a72561122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>,</td>\n",
       "      <td>32581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34305</th>\n",
       "      <td>the</td>\n",
       "      <td>26511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>.</td>\n",
       "      <td>25307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14550</th>\n",
       "      <td>a</td>\n",
       "      <td>12750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34565</th>\n",
       "      <td>to</td>\n",
       "      <td>12697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27636</th>\n",
       "      <td>of</td>\n",
       "      <td>12476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15249</th>\n",
       "      <td>and</td>\n",
       "      <td>11759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24312</th>\n",
       "      <td>in</td>\n",
       "      <td>10340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>''</td>\n",
       "      <td>6795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14549</th>\n",
       "      <td>``</td>\n",
       "      <td>6171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word  Count\n",
       "185      ,  32581\n",
       "34305  the  26511\n",
       "194      .  25307\n",
       "14550    a  12750\n",
       "34565   to  12697\n",
       "27636   of  12476\n",
       "15249  and  11759\n",
       "24312   in  10340\n",
       "5       ''   6795\n",
       "14549   ``   6171"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.groupby(by=['Word'], as_index=False)['Count'].sum().sort_values(by=['Count'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd24ce8-e439-4093-a7da-bc12c00fce07",
   "metadata": {},
   "source": [
    "\"nltk\" word_tokenize() does not work very well for this exercise, since we can see that it identifies special characters like ',', '.', etc., as words when they are not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "d51600bc-0144-40c1-959d-26899acb289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 2: Using regular expressions\n",
    "\n",
    "words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "words_df = pd.DataFrame(words, columns=['Word'])\n",
    "words_df['Count'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b6176c-2cc7-4422-a721-a9d8c6c95d05",
   "metadata": {},
   "source": [
    "Here, we have used a regular expression  to find sequences of word characters bounded by special non-word characters (blank spaces, commas, etc.). This regular expression considers a word any sequence of one or more characters.\n",
    "\n",
    "In addition, we are making sure that all characters in the text are lowercase, so we avoid situations in which we might treat words that are actually the same as different (e.g., \"There\" vs \"there\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "0b3f23a1-b351-4f4d-a33d-faeb4d1b1c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25485</th>\n",
       "      <td>the</td>\n",
       "      <td>29900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>a</td>\n",
       "      <td>13488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25751</th>\n",
       "      <td>to</td>\n",
       "      <td>12915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17781</th>\n",
       "      <td>of</td>\n",
       "      <td>12586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>and</td>\n",
       "      <td>12408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12983</th>\n",
       "      <td>in</td>\n",
       "      <td>11250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25482</th>\n",
       "      <td>that</td>\n",
       "      <td>6219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21999</th>\n",
       "      <td>s</td>\n",
       "      <td>5789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10359</th>\n",
       "      <td>for</td>\n",
       "      <td>5156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17873</th>\n",
       "      <td>on</td>\n",
       "      <td>4298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  Count\n",
       "25485   the  29900\n",
       "944       a  13488\n",
       "25751    to  12915\n",
       "17781    of  12586\n",
       "1826    and  12408\n",
       "12983    in  11250\n",
       "25482  that   6219\n",
       "21999     s   5789\n",
       "10359   for   5156\n",
       "17873    on   4298"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.groupby(by=['Word'], as_index=False)['Count'].sum().sort_values(by=['Count'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce344995-73ff-4733-b630-29f4e775b3a6",
   "metadata": {},
   "source": [
    "We can see how we have gotten rid of the special characters now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c132e05-7962-4ac9-8f99-fc68a4b334f1",
   "metadata": {},
   "source": [
    "##### 3. Find the Top 10 most common bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "a57195cc-7911-4504-a581-6b5bedcf0cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_shifted = words[1:]\n",
    "\n",
    "bigrams = pd.concat([pd.Series(words), pd.Series(words_shifted)], axis=1)\n",
    "\n",
    "bigrams['Bigram'] = bigrams[0] + ' ' + bigrams[1]\n",
    "bigrams['Count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "8e5b69c0-7725-46ee-8287-2a5da827819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_bigrams = bigrams.groupby(by=['Bigram'], as_index=False)['Count'].sum().sort_values(by=['Count'], ascending=False).head(10)\n",
    "top_10_bigrams = top_10_bigrams.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "756a00a7-c52f-47b6-94d8-c8602a70b0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>of the</td>\n",
       "      <td>3154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in the</td>\n",
       "      <td>2758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to the</td>\n",
       "      <td>1196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>on the</td>\n",
       "      <td>1159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for the</td>\n",
       "      <td>942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>and the</td>\n",
       "      <td>859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>in a</td>\n",
       "      <td>846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>it s</td>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>at the</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>to be</td>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Bigram  Count\n",
       "0   of the   3154\n",
       "1   in the   2758\n",
       "2   to the   1196\n",
       "3   on the   1159\n",
       "4  for the    942\n",
       "5  and the    859\n",
       "6     in a    846\n",
       "7     it s    776\n",
       "8   at the    773\n",
       "9    to be    743"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(top_10_bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcfd6c3-310d-45b0-89a1-3b4638b907cc",
   "metadata": {},
   "source": [
    "As expected, the top 10 bigrams found in the text are mostly combinations of prepositions and conjunctions with articles.\n",
    "\n",
    "The only notable exception is the top 10th diagram, which contains a combination of the preposition \"to\" with the infinitive of the verb \"be\", however that is probably one of the most if not the most used verbs in the English language."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
